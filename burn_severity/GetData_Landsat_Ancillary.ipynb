{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anniepeacock/DANSAR/blob/devel/burn_severity/GetData_Landsat_Ancillary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Voknq5nH02ME"
      },
      "source": [
        "# **Remote Sensing of Wildfires: Landsat & Ancillary data for comparison with SAR**\n",
        "\n",
        "*This notebook describes how to get the Landsat and relevant ancillary datasets over the Verdugo Mountains, Los Angeles for a comparison with SAR fire burn severity for the 2017 La Tuna Fire.*\n",
        "\n",
        "Pre-processing steps to prepare data for this comparison/analysis\n",
        "\n",
        "* Resample BAER & MTBS Landsat to UAVSAR extent & resolution\n",
        "* Calculate UAVSAR-matching dNBR dates with Landsat\n",
        "* Fire perimeter\n",
        "* mountain extent\n",
        "* vegetation type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WYbI9c0yZHI"
      },
      "source": [
        "## Running the Notebook\n",
        "- This Notebook has both \"text\" and \"code\" cells. The text cells have text descriptions about running the notebooks and data interpretation.\n",
        "- Code cells are a light gray and a \"play\" button appears in the upper left corner when your mouse is hovered over the cell.\n",
        "- To run the content in the code cells, **select the play button** in the upper left corner of each code cell or **press shift-enter**.\n",
        "- The figures and histograms are interactable via mouse/touch pad actions. Interactable functions can be selected on the top right corners of each figure.\n",
        "\n",
        "This routine uses the following python libraries. Some are already included in the Google Colab environment and others are installed in the cell below before imported. Downloading new python packages to this environment may take a few seconds to complete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgtz8Eie2vSR"
      },
      "source": [
        "<a name=\"s2\"></a>\n",
        "# 1. Downloading / Generating Files used in Analysis\n",
        "\n",
        "1. BAER and MTBS Products originally downloaded from: https://burnseverity.cr.usgs.gov/viewer/?product=BAER\n",
        "  * Fire ID: ca3429511836120170901\n",
        "2. Calculated dNBR from UAVSAR-like dates with Landsat 8:\n",
        "  * Script in GEE to generate dNBR with UAVSAR-like dates: https://code.earthengine.google.com/15eb2d2fa9e0a6649b145ce8e4c2ac30\n",
        "    * dNBR geotiff is exported from GEE to Google Drive, then read in to this script to be resampled and subset to match the SAR datasets\n",
        "  * Script Source: https://www.un-spider.org/advisory-support/recommended-practices/recommended-practice-burn-severity/burn-severity-earth-engine\n",
        "3. Fire perimeter downloaded from the NIFC: https://data-nifc.opendata.arcgis.com/datasets/historic-perimeters-2017/explore\n",
        "4. The geojson of the extent of the Verdugo Mountains was generated by tracing the extent of the mountains\n",
        "5. CalVeg Download: https://www.fs.usda.gov/detail/r5/landmanagement/resourcemanagement/?cid=stelprdb5347192\n",
        "  * https://data.fs.usda.gov/geodata/edw/datasets.php\n",
        "  * Existing Vegetation: Region 5 - South Coast for Los Angeles\n",
        "6. Processed UAVSAR and data stacks are staged here: https://uavsar.jpl.nasa.gov/cgi-bin/sar-notebooks.pl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio --quiet"
      ],
      "metadata": {
        "id": "g9CsB3yj9K_-",
        "outputId": "654ed453-afe1-48e9-b3e9-f78de19492d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio as rio\n",
        "from rasterio.warp import reproject, Resampling\n",
        "from rasterio.mask import mask\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import box, mapping"
      ],
      "metadata": {
        "id": "qFxwUIrA9HnC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "60LW4z6S873o",
        "outputId": "e7c476e7-12c7-4c4d-c5d9-1e308498ae93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Landsat Fire Severity Products"
      ],
      "metadata": {
        "id": "RR1kp_7whdq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dNBR for UAVSAR dates (2014 & 2017) 30 meter resolution\n",
        "!wget https://uavsar.jpl.nasa.gov/SAR_NOTEBOOKS/Fire/dnbr_2014_2017.tif --quiet\n",
        "\n",
        "# UAVSAR stack\n",
        "!wget https://uavsar.jpl.nasa.gov/SAR_NOTEBOOKS/Fire/6m_stack.tif  --quiet\n",
        "\n",
        "# NISAR Simulated stack\n",
        "nisar_sim_path = ('/content/drive/MyDrive/UAVSAR_Science/LaTuna_Fire/GIS_Files/2024_data/nisarsim_stack.tif')\n",
        "nisar_sim = rio.open(nisar_sim_path).read(1)"
      ],
      "metadata": {
        "id": "c_H6I0P9nmM8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate UAVSAR-resolution Landsat Fire Severity Products"
      ],
      "metadata": {
        "id": "ucwJ6jpL_Fvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the target raster (6m_stack.tif) to extract its pixel size and extent\n",
        "with rio.open(\"6m_stack.tif\") as target_src:\n",
        "    target_band = target_src.read(1)  # Choose the band you want to match\n",
        "    target_profile = target_src.profile\n",
        "    target_transform = target_src.transform\n",
        "    target_crs = target_src.crs\n",
        "    target_extent = target_src.bounds\n",
        "\n",
        "    # Create a Polygon from the bounding box coordinates\n",
        "    target_polygon = box(*target_extent)\n",
        "\n",
        "# Open the source raster (dnbr_2014_2017.tif) to be resampled\n",
        "with rio.open(\"dnbr_2014_2017.tif\") as src:\n",
        "    # Perform resampling to match the pixel size and extent of the target band\n",
        "    resampled_data = src.read(\n",
        "        out_shape=(target_band.shape[0], target_band.shape[1]),\n",
        "        resampling=Resampling.nearest\n",
        "    )\n",
        "\n",
        "    # Define the transform for the resampled raster\n",
        "    new_transform = target_transform\n",
        "\n",
        "    # Prepare the resampled profile\n",
        "    resampled_profile = src.profile.copy()\n",
        "    resampled_profile.update({\n",
        "        'width': target_band.shape[1],\n",
        "        'height': target_band.shape[0],\n",
        "        'transform': new_transform,\n",
        "        'crs': target_crs\n",
        "    })\n",
        "\n",
        "    # Clip the resampled raster to the same extent as the target raster\n",
        "    clipped_data, clipped_transform = mask(\n",
        "        dataset=src,\n",
        "        shapes=[mapping(target_polygon)],\n",
        "        crop=True,\n",
        "        filled=False\n",
        "    )\n",
        "\n",
        "    # Update the profile with the clipped transform and dimensions\n",
        "    resampled_profile.update({\n",
        "        'width': clipped_data.shape[2],\n",
        "        'height': clipped_data.shape[1],\n",
        "        'transform': clipped_transform\n",
        "    })\n",
        "\n",
        "    # Write the clipped and resampled raster to a new GeoTIFF file\n",
        "    with rio.open(\"dnbr_sar_dates_resampled_uavsar.tif\", 'w', **resampled_profile) as dst:\n",
        "        dst.write(clipped_data)\n",
        "\n",
        "\n",
        "## Add MTBS and BARC"
      ],
      "metadata": {
        "id": "GpyMZvOkBOWQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate NISAR Simulated Resolution Landsat Fire Severity Products"
      ],
      "metadata": {
        "id": "22IKeWR-_QtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the target raster (6m_stack.tif) to extract its pixel size and extent\n",
        "with rio.open('/content/drive/MyDrive/UAVSAR_Science/LaTuna_Fire/GIS_Files/2024_data/nisarsim_stack.tif') as target_src:\n",
        "    target_band = target_src.read(1)  # Choose the band you want to match\n",
        "    target_profile = target_src.profile\n",
        "    target_transform = target_src.transform\n",
        "    target_crs = target_src.crs\n",
        "    target_extent = target_src.bounds\n",
        "\n",
        "    # Create a Polygon from the bounding box coordinates\n",
        "    target_polygon = box(*target_extent)\n",
        "    print(target_polygon)\n",
        "# Open the source raster (dnbr_2014_2017.tif) to be resampled\n",
        "with rio.open(\"dnbr_2014_2017.tif\") as src:\n",
        "    # Perform resampling to match the pixel size and extent of the target band\n",
        "    resampled_data = src.read(\n",
        "        out_shape=(target_band.shape[0], target_band.shape[1]),\n",
        "        resampling=Resampling.nearest\n",
        "    )\n",
        "\n",
        "    # Define the transform for the resampled raster\n",
        "    new_transform = target_transform\n",
        "\n",
        "    # Prepare the resampled profile\n",
        "    resampled_profile = src.profile.copy()\n",
        "    resampled_profile.update({\n",
        "        'width': target_band.shape[1],\n",
        "        'height': target_band.shape[0],\n",
        "        'transform': new_transform,\n",
        "        'crs': target_crs\n",
        "    })\n",
        "\n",
        "    # Clip the resampled raster to the same extent as the target raster\n",
        "    clipped_data, clipped_transform = mask(\n",
        "        dataset=src,\n",
        "        shapes=[mapping(target_polygon)],\n",
        "        crop=True,\n",
        "        filled=False\n",
        "    )\n",
        "\n",
        "    # Update the profile with the clipped transform and dimensions\n",
        "    resampled_profile.update({\n",
        "        'width': clipped_data.shape[2],\n",
        "        'height': clipped_data.shape[1],\n",
        "        'transform': clipped_transform\n",
        "    })\n",
        "\n",
        "    # Write the clipped and resampled raster to a new GeoTIFF file\n",
        "    with rio.open(\"dnbr_sar_dates_resampled_nisarsim.tif\", 'w', **resampled_profile) as dst:\n",
        "        dst.write(clipped_data)\n",
        "\n",
        "\n",
        "## Add MTBS and BARC"
      ],
      "metadata": {
        "id": "B4ZywJGQ_ZaC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Rasterized Data Stack of Fire Perimeter, Verdugo Mountains Perimeter"
      ],
      "metadata": {
        "id": "tfY6JNIZANhG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ogQcyllGAaQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CalVeg"
      ],
      "metadata": {
        "id": "hO8bC0TJS5FE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "\n",
        "# Read GeoJSON file\n",
        "gdf = gpd.read_file(\"calveg_latuna.geojson\")\n",
        "\n",
        "# Print dataframe header\n",
        "print(gdf.head())\n",
        "\n",
        "# Column - 'REGIONAL_DOMINACE_TYPE\n"
      ],
      "metadata": {
        "id": "KmTJLJgdS6bm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}